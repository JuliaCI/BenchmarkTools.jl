<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · BenchmarkTools.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://JuliaCI.github.io/BenchmarkTools.jl/reference/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/indigo.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">BenchmarkTools.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../manual/">Manual</a></li><li><a class="tocitem" href="../linuxtips/">Linux-based environments</a></li><li class="is-active"><a class="tocitem" href>Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/master/docs/src/reference.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="Base.run" href="#Base.run"><code>Base.run</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">run(b::Benchmark[, p::Parameters = b.params]; kwargs...)</code></pre><p>Run the benchmark defined by <a href="#BenchmarkTools.@benchmarkable-Tuple"><code>@benchmarkable</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L111-L115">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.run-Tuple{BenchmarkGroup, Vararg{Any, N} where N}" href="#Base.run-Tuple{BenchmarkGroup, Vararg{Any, N} where N}"><code>Base.run</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">run(group::BenchmarkGroup[, args...]; verbose::Bool = false, pad = &quot;&quot;, kwargs...)</code></pre><p>Run the benchmark group, with benchmark parameters set to <code>group</code>&#39;s by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L119-L123">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools._withprogress-Tuple{Any, AbstractString, BenchmarkGroup}" href="#BenchmarkTools._withprogress-Tuple{Any, AbstractString, BenchmarkGroup}"><code>BenchmarkTools._withprogress</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">_withprogress(
    name::AbstractString,
    group::BenchmarkGroup;
    kwargs...,
) do progressid, nleaves, ndone
    ...
end</code></pre><p>Execute do block with following arguments:</p><ul><li><code>progressid</code>: logging ID to be used for <code>@logmsg</code>.</li><li><code>nleaves</code>: total number of benchmarks counted at the root benchmark group.</li><li><code>ndone</code>: number of completed benchmarks</li></ul><p>They are either extracted from <code>kwargs</code> (for sub-groups) or newly created (for root benchmark group).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L44-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.tune!" href="#BenchmarkTools.tune!"><code>BenchmarkTools.tune!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">tune!(b::Benchmark, p::Parameters = b.params; verbose::Bool = false, pad = &quot;&quot;, kwargs...)</code></pre><p>Tune a <code>Benchmark</code> instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L241-L245">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.tune!-Tuple{BenchmarkGroup}" href="#BenchmarkTools.tune!-Tuple{BenchmarkGroup}"><code>BenchmarkTools.tune!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tune!(group::BenchmarkGroup; verbose::Bool = false, pad = &quot;&quot;, kwargs...)</code></pre><p>Tune a <code>BenchmarkGroup</code> instance. For most benchmarks, <code>tune!</code> needs to perform many evaluations to determine the proper parameters for any given benchmark - often more evaluations than are performed when running a trial. In fact, the majority of total benchmarking time is usually spent tuning parameters, rather than actually running trials.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L210-L218">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.@ballocated-Tuple" href="#BenchmarkTools.@ballocated-Tuple"><code>BenchmarkTools.@ballocated</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@ballocated expression [other parameters...]</code></pre><p>Similar to the <code>@allocated</code> macro included with Julia, this returns the number of bytes allocated when executing a given expression.   It uses the <code>@benchmark</code> macro, however, and accepts all of the same additional parameters as <code>@benchmark</code>.  The returned allocations correspond to the trial with the <em>minimum</em> elapsed time measured during the benchmark.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L528-L538">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.@belapsed-Tuple" href="#BenchmarkTools.@belapsed-Tuple"><code>BenchmarkTools.@belapsed</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@belapsed expression [other parameters...]</code></pre><p>Similar to the <code>@elapsed</code> macro included with Julia, this returns the elapsed time (in seconds) to execute a given expression.   It uses the <code>@benchmark</code> macro, however, and accepts all of the same additional parameters as <code>@benchmark</code>.  The returned time is the <em>minimum</em> elapsed time measured during the benchmark.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L512-L521">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.@benchmark-Tuple" href="#BenchmarkTools.@benchmark-Tuple"><code>BenchmarkTools.@benchmark</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@benchmark &lt;expr to benchmark&gt; [setup=&lt;setup expr&gt;]</code></pre><p>Run benchmark on a given expression.</p><p><strong>Example</strong></p><p>The simplest usage of this macro is to put it in front of what you want to benchmark.</p><pre><code class="language-julia-repl">julia&gt; @benchmark sin(1)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     13.610 ns (0.00% GC)
  median time:      13.622 ns (0.00% GC)
  mean time:        13.638 ns (0.00% GC)
  maximum time:     21.084 ns (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     998</code></pre><p>You can interpolate values into <code>@benchmark</code> expressions:</p><pre><code class="language-julia"># rand(1000) is executed for each evaluation
julia&gt; @benchmark sum(rand(1000))
BenchmarkTools.Trial:
  memory estimate:  7.94 KiB
  allocs estimate:  1
  --------------
  minimum time:     1.566 μs (0.00% GC)
  median time:      2.135 μs (0.00% GC)
  mean time:        3.071 μs (25.06% GC)
  maximum time:     296.818 μs (95.91% GC)
  --------------
  samples:          10000
  evals/sample:     10

# rand(1000) is evaluated at definition time, and the resulting
# value is interpolated into the benchmark expression
julia&gt; @benchmark sum($(rand(1000)))
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     101.627 ns (0.00% GC)
  median time:      101.909 ns (0.00% GC)
  mean time:        103.834 ns (0.00% GC)
  maximum time:     276.033 ns (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     935</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L324-L381">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.@benchmarkable-Tuple" href="#BenchmarkTools.@benchmarkable-Tuple"><code>BenchmarkTools.@benchmarkable</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@benchmarkable &lt;expr to benchmark&gt; [setup=&lt;setup expr&gt;]</code></pre><p>Create a <code>Benchmark</code> instance for the given expression. <code>@benchmarkable</code> has similar syntax with <code>@benchmark</code>. See also <a href="#BenchmarkTools.@benchmark-Tuple"><code>@benchmark</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L423-L428">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.@benchmarkset-Tuple{Any, Any}" href="#BenchmarkTools.@benchmarkset-Tuple{Any, Any}"><code>BenchmarkTools.@benchmarkset</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@benchmarkset &quot;title&quot; begin ... end</code></pre><p>Create a benchmark set, or multiple benchmark sets if a <code>for</code> loop is provided.</p><p><strong>Examples</strong></p><pre><code class="language-julia">@benchmarkset &quot;suite&quot; for k in 1:5
    @case &quot;case $k&quot; rand($k, $k)
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/groups.jl#L308-L320">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.@btime-Tuple" href="#BenchmarkTools.@btime-Tuple"><code>BenchmarkTools.@btime</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@btime expression [other parameters...]</code></pre><p>Similar to the <code>@time</code> macro included with Julia, this executes an expression, printing the time it took to execute and the memory allocated before returning the value of the expression.</p><p>Unlike <code>@time</code>, it uses the <code>@benchmark</code> macro, and accepts all of the same additional parameters as <code>@benchmark</code>.  The printed time is the <em>minimum</em> elapsed time measured during the benchmark.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/execution.jl#L545-L557">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BenchmarkTools.@case-Tuple{Any, Vararg{Any, N} where N}" href="#BenchmarkTools.@case-Tuple{Any, Vararg{Any, N} where N}"><code>BenchmarkTools.@case</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@case title &lt;expr to benchmark&gt; [setup=&lt;setup expr&gt;]</code></pre><p>Mark an expression as a benchmark case. Must be used inside <a href="#BenchmarkTools.@benchmarkset-Tuple{Any, Any}"><code>@benchmarkset</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/51a918d1e85eff46a793717b1f91150da5098200/src/groups.jl#L325-L329">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../linuxtips/">« Linux-based environments</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.3 on <span class="colophon-date" title="Monday 5 July 2021 14:54">Monday 5 July 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
